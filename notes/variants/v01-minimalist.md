# AI 全栈工程师 3 个月成长指南 — 极简主义版

> 少即是多。不做 12 个项目，只做 3 个，但每个都做到产品级。
> 面试时你能把一个项目讲 30 分钟不重复——因为你真的把它做透了。

---

## 你的起点和终点

**起点**：CS 大四，有运维经验，MacBook Pro M5 32GB 2TB，会用终端，懂 Linux 基础。
**终点**：3 个月后，你有 3 个产品级作品（有真实用户、有线上部署、有数据支撑），3 篇深度技术文章（3000-5000 字），一个能互动的作品集网站。面试官问任何一个项目，你都能讲半小时。

---

## 能力分层：7+2

**基本功**（AI 替代不了）
1. **算法思维** — 能判断 AI 生成的代码好不好，能讲清楚时间空间复杂度
2. **系统设计** — 能画出数据流，能说清楚每个架构决策的 trade-off
3. **技术写作** — 把做过的事讲清楚，这个能力复利一辈子

**必备技能**（在 3 个项目中自然习得）
4. **TypeScript 全栈** — Next.js + API + 数据库，一套 TS 打通
5. **AI 集成** — 流式输出、Prompt 工程、RAG、Embedding
6. **DevOps** — 你已有的优势，在项目中放大它
7. **AI 辅助开发** — Claude Code / Cursor 把效率拉到 3-5 倍

**加分项**（有了脱颖而出）
8. **本地 AI** — M5 32GB 跑本地模型，大多数应届生没这个条件
9. **开源贡献** — 给别人的项目提过 PR，证明你能在真实协作中写代码

**极简策略：3 个项目覆盖全部 9 项能力，每项能力至少被 2 个项目触及。**

---

## 第 0 步：把 Mac 变成开发武器

拿到电脑的第一天，别急着写代码。先把环境搞利索。

### 科学上网

你已经有 ghelper 代理。装一个 Clash Verge Rev 作为客户端：
- 从 GitHub Releases 下载 dmg 安装
- 导入订阅链接，开启系统代理 + 增强模式
- 测试：`curl -I https://www.google.com` 能通就行

### 开发环境

```bash
# Homebrew
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# 核心工具
brew install git node bun ollama
brew install --cask cursor warp visual-studio-code

# AI 编程工具
npm install -g @anthropic-ai/claude-code

# 本地模型（利用你的 32GB）
ollama pull qwen2.5:14b
ollama pull llama3.1:8b

# 验证
bun --version && node --version && git --version && ollama list
```

### 账号注册

全部用 GitHub 账号登录：
- **Vercel** — 部署平台，免费额度够用
- **Neon** — PostgreSQL 数据库，免费 tier
- **GitHub** — 代码托管，开启 2FA
- **Claude** — AI API（或用 DeepSeek 作为平替）

---

## 核心理念：3 个项目，4 轮迭代

每个项目用 4 周深度打磨，从 v0.1 到 v3.0。不是做完就扔，是反复迭代到产品级。

每轮迭代的节奏：
- **v0.1**（第 1 周）— 最小可用版本，核心功能跑通，部署上线
- **v1.0**（第 2 周）— 补齐功能，加认证、数据库、错误处理
- **v2.0**（第 3 周）— 性能优化、UI 打磨、加监控和日志
- **v3.0**（第 4 周）— 产品级：有用户反馈、有数据、写深度文章

---

## 项目 1：AI 全栈作品集网站（Week 1-4）

> 你的线上门面 + AI 原生交互体验。面试官第一个看的东西。

### 解决什么问题
面试官搜你名字，看到一个专业的、能互动的个人网站——不是静态简历，是一个有 AI 聊天助手的活产品。

### 能力覆盖
C2 系统设计 | C3 技术写作 | C4 TypeScript 全栈 | C5 AI 集成 | C6 DevOps | C7 AI 辅助开发

### 迭代路线

**v0.1 — 最小上线版**
- `bunx create-next-app`，Tailwind + shadcn/ui
- 首页 + 关于我 + 项目列表（硬编码数据）
- Vercel 一键部署，绑定自定义域名
- 目标：24 小时内上线

**v1.0 — 全栈化**
- 加 PostgreSQL（Neon）+ Drizzle ORM，项目数据入库
- Better Auth 认证（为管理后台准备）
- Markdown 技术博客系统（MDX）
- Server Actions 处理表单
- GitHub Actions CI/CD 流水线

**v2.0 — AI 原生**
- 集成 AI 聊天助手：访客可以问关于你的任何问题
- Vercel AI SDK 流式输出 + 上下文管理
- RAG：把你的简历、项目文档、文章喂给 AI 作为知识库
- Embedding + 向量检索（用 Neon pgvector）
- 响应式设计、SEO 优化、性能调优（Lighthouse 90+）

**v3.0 — 产品级**
- 访客分析仪表盘（哪些项目被看最多）
- AI 对话记录分析（面试官最常问什么）
- Docker 容器化 + 自托管备选方案
- 分享给 10 个人收集反馈，根据反馈迭代

### 面试怎么讲
- "我做了一个 AI 原生的个人网站，集成了 RAG 聊天助手"
- 能讲：全栈架构、SSR vs SSG 选择、AI 流式传输实现、RAG 检索策略、部署方案对比
- 系统设计题"设计一个聊天系统"→ 直接讲你的 AI 助手架构

---

## 项目 2：智能文档问答平台（Week 5-8）

> 完整的 RAG 产品。上传任何文档，和它对话。这是 AI 工程面试的硬通货。

### 解决什么问题
技术文档太长不想读，论文看不懂想问问题，公司内部知识库检索效率低——上传文档，直接对话。

### 能力覆盖
C1 算法思维 | C2 系统设计 | C4 TypeScript 全栈 | C5 AI 集成 | C7 AI 辅助开发 | C8 本地 AI

### 迭代路线

**v0.1 — 最小 RAG**
- 单文件上传（PDF/TXT）→ 文本分块 → Embedding → 存储 → 检索 → LLM 回答
- 用 Ollama 本地模型做 Embedding 和生成（零成本开发）
- 简单的聊天界面，能问能答就行
- 部署到 Vercel

**v1.0 — 多文档 + 多模型**
- 支持多文档上传，文档管理界面
- 云端模型（Claude API）+ 本地模型（Ollama）双通道
- 对话历史持久化（PostgreSQL）
- 分块策略优化：滑动窗口、语义分块
- 用户认证，每人独立的文档空间

**v2.0 — 检索增强**
- 混合检索：向量检索 + 关键词检索（BM25）
- 重排序（Reranking）提升检索精度
- 引用溯源：回答标注来自文档的哪一段
- 本地模型竞技场：同一问题对比多个模型的回答质量
- 性能监控：检索延迟、生成延迟、准确率追踪

**v3.0 — 产品级**
- 多用户 SaaS 化：免费 tier + 付费 tier 的架构设计
- API 接口开放，支持第三方集成
- Docker Compose 一键自部署方案
- 找 5 个同学试用，收集真实使用数据
- 写一份完整的技术架构文档

### 面试怎么讲
- "我做了一个完整的 RAG 文档问答平台，支持混合检索和多模型对比"
- 能讲：Embedding 原理、分块策略对比、检索精度优化、向量数据库选型、流式架构
- 系统设计题"设计一个 AI 应用"→ 直接讲 RAG 架构和优化过程
- 行为面试"讲一个有挑战的项目"→ 讲检索精度从 60% 优化到 85% 的过程

---

## 项目 3：AI DevOps 工具链（Week 9-12）

> 把你的运维经验产品化。CLI + GitHub Bot + 监控，三合一。

### 解决什么问题
每次部署新项目要重复配置，PR 没人 review，日志分析靠肉眼——用 AI 把这些全自动化。

### 能力覆盖
C1 算法思维 | C2 系统设计 | C3 技术写作 | C5 AI 集成 | C6 DevOps | C8 本地 AI | C9 开源贡献

### 迭代路线

**v0.1 — 部署 CLI**
- 交互式 CLI：选择技术栈 → 自动生成 Dockerfile + docker-compose.yml + GitHub Actions
- 支持 Next.js / Node.js / Python 三种模板
- Commander.js + Inquirer.js 实现
- 发布到 npm，`npx your-deploy-cli` 即可使用

**v1.0 — GitHub Code Review Bot**
- GitHub App：监听 PR 事件
- 读取 PR diff → AI 分析代码质量 → 自动评论
- 支持自定义 review 规则（.reviewrc 配置文件）
- Webhook 接收 + Vercel Serverless 处理
- 在自己的项目上先用起来

**v2.0 — 智能日志分析**
- 接入日志流（支持 JSON 格式日志）
- AI 实时分析异常模式，自动生成告警摘要
- 仪表盘展示：错误趋势、异常分类、根因分析建议
- 本地模型处理敏感日志（数据不出本机）
- MCP Server 实现，可被其他 AI 工具调用

**v3.0 — 产品级 + 开源**
- 三个子工具统一品牌，monorepo 管理
- 完整的 README、Contributing Guide、LICENSE
- 发布到 npm + GitHub，打上 release tag
- 给一个你用过的开源项目（shadcn/ui、Drizzle 等）提一个 PR
- 在 Dev.to 发英文介绍文章，吸引 star

### 面试怎么讲
- "我把运维经验产品化，做了一套 AI DevOps 工具链并开源"
- 能讲：CLI 设计、GitHub API、Webhook 架构、日志分析算法、MCP 协议
- 系统设计题"设计一个 CI/CD 系统"→ 直接讲你的部署 CLI 架构
- 行为面试"你的 DevOps 经验"→ 从运维到产品化的完整故事
- 开源贡献经历 → 证明你能在别人的代码库里工作

---

## 能力覆盖矩阵

```
能力              项目1(网站)  项目2(RAG)  项目3(DevOps)
C1 算法思维                     ★★         ★★
C2 系统设计        ★★          ★★★        ★★
C3 技术写作        ★★                      ★★★
C4 TS 全栈         ★★★         ★★★
C5 AI 集成         ★★          ★★★        ★★
C6 DevOps          ★★                      ★★★
C7 AI 辅助开发     ★★★         ★★★        ★★
C8 本地 AI                      ★★★        ★★
C9 开源贡献                                 ★★★
```

每项能力至少被 2 个项目覆盖。3 个项目，9 项能力，无死角。

---

## 3 篇深度技术文章（3000-5000 字）

不写 12 篇水文，写 3 篇能被搜索引擎收录、能帮到别人的深度长文。

### 文章 1：《从零到产品级：一个 AI 原生个人网站的 4 次迭代》
- 对应项目 1，Week 4 完成
- 内容：架构演进（v0.1→v3.0）、RAG 聊天助手实现、SSR/SSG 选择、性能优化实战
- 亮点：不是教程，是一个产品从 MVP 到成熟的真实记录
- 发布：个人网站 + 掘金

### 文章 2：《RAG 实战：从 60% 到 85% 检索准确率的优化之路》
- 对应项目 2，Week 8 完成
- 内容：分块策略对比、混合检索实现、Reranking 效果、本地 vs 云端模型对比数据
- 亮点：有数据、有对比、有结论——不是"我用了 RAG"，是"我优化了 RAG"
- 发布：个人网站 + 掘金 + Dev.to（英文版）

### 文章 3：《把运维经验变成开源产品：一个 AI DevOps 工具链的设计与实现》
- 对应项目 3，Week 12 完成
- 内容：CLI 设计哲学、GitHub Bot 架构、MCP 协议实践、开源发布流程
- 亮点：展示从"会用工具"到"造工具"的跨越，附开源贡献经历
- 发布：个人网站 + Dev.to（英文版）+ GitHub README

### 写作公式

```
深度文章 = 真实问题 + 多次尝试的过程 + 有数据支撑的结论 + 可复用的方法论
```

每篇文章的结构：
1. **问题定义**（300 字）— 为什么做这个，解决什么痛点
2. **架构设计**（500 字）— 整体方案，关键决策的 trade-off
3. **实现细节**（1500 字）— 核心代码、踩过的坑、解决方案
4. **数据与对比**（500 字）— 性能数据、方案对比、优化效果
5. **反思与总结**（200 字）— 如果重来会怎么做，可复用的经验

---

## 时间节奏

```
Week 0        环境搭建 + 科学上网 + 账号注册
Week 1-4      项目 1：AI 全栈作品集网站（v0.1 → v3.0）+ 文章 1
Week 5-8      项目 2：智能文档问答平台（v0.1 → v3.0）+ 文章 2
Week 9-12     项目 3：AI DevOps 工具链（v0.1 → v3.0）+ 文章 3
```

### 每日节奏

上午 3h 项目开发 → 下午 2h 项目开发 + 代码审查 → 晚上 30min LeetCode + 60min 文章写作

LeetCode 每天 1 题，Week 1-4 Easy，Week 5-8 Medium，Week 9-12 复习 + Hard。目标 80+ 题，每题能讲清思路。

投递节奏：Week 4 投练手公司 → Week 8 投目标公司 → Week 11-12 密集面试，每场后 24h 写复盘。

---

## AI 辅助开发工作流

### 工作流

```
你定义问题和架构 → AI 生成代码 → 你审查修改 → AI 生成测试 → 你部署上线 → 你写文章
     (C2)              (C7)          (C1)           (C7)         (C6)         (C3)
```

### 工具

| 工具 | 什么时候用 |
|------|-----------|
| Claude Code | 复杂任务：架构设计、多文件修改、代码审查 |
| Cursor | 日常写代码：补全、内联编辑、快速问答 |
| v0.dev | 前端 UI：描述你要什么组件，直接生成 |
| Ollama | 本地模型：项目 2 和项目 3 的核心依赖 |

### 边界

- AI 生成的每一行代码你都要能解释——面试官会问
- 遇到不懂的地方停下来搞懂，不要跳过
- 记录你和 AI 的协作过程——这本身就是文章素材
- AI 帮你写得更快，不是帮你跳过理解

---

## 技术栈

一套 TypeScript 打通全栈，不折腾多语言。

| 层 | 选择 | 为什么 |
|----|------|--------|
| 语言 | TypeScript | 类型安全，前后端统一 |
| 框架 | Next.js 15 | 全栈一体，SSR/SSG/API 都有 |
| UI | Tailwind + shadcn/ui | 快，好看，可定制 |
| 数据库 | PostgreSQL (Neon) + Drizzle | Serverless 友好，TS 原生 ORM |
| 向量 | Neon pgvector | 和主数据库统一，不额外引入依赖 |
| AI | Vercel AI SDK + Ollama | 云端流式 + 本地推理 |
| 部署 | Vercel + Docker | 零配置 + 容器化 |
| CI/CD | GitHub Actions | 行业标准 |
| 运行时 | Bun | 快 |

---

> 核心哲学：做少做精。3 个产品级作品 > 12 个 demo 级项目。面试官不在乎你做了多少，在乎你能讲多深。当你能把一个项目从 v0.1 讲到 v3.0，把每个架构决策的 why 讲清楚，你就赢了。
